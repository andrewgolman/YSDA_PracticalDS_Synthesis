{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fcebaa0",
   "metadata": {
    "id": "7fcebaa0"
   },
   "source": [
    "# Multi-speaker speech synthesis\n",
    "\n",
    "В этом задании мы создадим датасет для синтеза речи и обучим на нем мультиспикерную модель.\n",
    "\n",
    "Мы уже написали/скопипастили в этот ноутбук много релевантного кода, большая часть из которого взята из [репозитория FastSpeech2](https://github.com/ming024/FastSpeech2). Вам придется:\n",
    "\n",
    "- запускать этот код, визуализировать данные и принимать решения - как разбить данные, какое распределение должно быть у фичей\n",
    "\n",
    "- запускать инференс обученной модели\n",
    "\n",
    "Некоторые части кода нужно будет все-таки заполнить - это поможет лучше разобраться в том, как получаются фичи и как учится модель синтеза. Рекомендуем разобраться в коде внутри этого ноутбука. Также можно смотреть и на другие файлы этого репозитория.\n",
    "\n",
    "### Основные части задания:\n",
    "1. Создание датасета (2 балла). Мы нашли для вас несколько видео с речью знаменитостей - но это длинные дорожки по полчаса. Нужно сделать из них пригодные для обучения данные.\n",
    "2. Генерация фичей (2 балла). Извлекаем информацию про интонацию и скорость речи.\n",
    "3. Обучение модели синтеза (3 балла). На это может уйти до 10 часов - не оставляйте задание на последний вечер!\n",
    "4. Анализ результатов (8 баллов): меняем интонацию, смотрим на ошибки модели.\n",
    "\n",
    "### Про модель синтеза\n",
    "\n",
    "![alt text](synthesized_melspectrogram.png \"Mel Spectrogram\")\n",
    "\n",
    "В качестве модели синтеза мы будем учить [FastSpeech2](https://arxiv.org/abs/2006.04558). На выход она выдает [мел-спектрограмму](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53). Напомним, как она строится:\n",
    "\n",
    "- дана звуковая волна размерности `sample_rate` значений в секунду\n",
    "- она разбивается на промежутки размера `window_length`\n",
    "- левые границы промежутков находятся на расстоянии `hop_length` друг от друга\n",
    "- по каждому промежутку считается FFT, после логарифмирования и перевода в mel-базис получается вектор (будем называть его фреймом)\n",
    "- вектора конкатенируются, таким образом по горизонтальной оси в мел-спеке идет время.\n",
    "\n",
    "Преобразованием мел-спеки в аудио занимается отдельная модель - вокодер. В этом ноутбуке мы используем предобученный [MelGAN](https://arxiv.org/abs/1910.06711).\n",
    "\n",
    "#### Входы модели\n",
    "\n",
    "\n",
    "1. список фонем\n",
    "\n",
    "2. длины всех фонем (alignment). Мы считаем, что каждой фонеме соответствует целое число фреймов.\n",
    "\n",
    "3. интонационные фичи ([f0](https://wiki.aalto.fi/pages/viewpage.action?pageId=149890776) и energy), посчитанные для каждого фрейма\n",
    "\n",
    "4. эмбеддинг спикера\n",
    "\n",
    "Пункты (2) и (3) наша модель будет уметь предсказывать. Но примеры из валидационного датасета можно будет синтезировать как с предсказанными, так и с ground truth фичами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d56530",
   "metadata": {
    "id": "a2d56530"
   },
   "source": [
    "# 0. Готовим данные и окружение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef93683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/andrewgolman/YSDA_PracticalDS_Synthesis.git\n",
    "# for colab\n",
    "%cd YSDA_PracticalDS_Synthesis\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3151c",
   "metadata": {
    "id": "d5a3151c"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3dcae",
   "metadata": {
    "id": "6fa3dcae"
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"ysda_books_data\")\n",
    "base_path = Path(\"dataset/\")\n",
    "vctk_path = Path(\"vctk_data/\")\n",
    "!mkdir {base_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e398e4",
   "metadata": {
    "id": "c1e398e4"
   },
   "outputs": [],
   "source": [
    "# # # books and celebs data\n",
    "!wget https://intone-public-data.s3.us-east-2.amazonaws.com/ysda_books_data.zip\n",
    "!unzip ysda_books_data.zip -d {data_path}\n",
    "!mv {data_path}/shad_data/* {data_path}\n",
    "\n",
    "# # # features from VCTK\n",
    "!wget https://intone-public-data.s3.us-east-2.amazonaws.com/vctk_features.zip\n",
    "!unzip vctk_features.zip -d {vctk_path}\n",
    "!mv {vctk_path}/vctk_base_256/* {vctk_path}\n",
    "\n",
    "# # # audio from VCTK\n",
    "!wget https://intone-public-data.s3.us-east-2.amazonaws.com/vctk_audio.zip \n",
    "!unzip vctk_audio.zip -d vctk_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8443a",
   "metadata": {
    "id": "7ba8443a"
   },
   "outputs": [],
   "source": [
    "data_cfg = OmegaConf.load(\"conf/data.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1792bd",
   "metadata": {
    "id": "ad1792bd"
   },
   "source": [
    "#  1. Подготовка датасета\n",
    "\n",
    "### 1.1 Разбиение данных\n",
    "Мы будем обучаться на двух датасетах.\n",
    "\n",
    "1. VCTK - популярный в рисерче датасет для мультиспикерного синтеза. Посмотрите как он устроен, послушайте примеры из него - обычно это короткие предложения по 3-7 секунд (что узнать точнее, можно посмотреть на распределение длин записей).\n",
    "2. Датасет, создаваемый в этом ноутбуке. Мы собрали несколько аудиокниг, а также записей селебрити - вы можете также добавить в датасет любые свои записи, включая собственный голос. Также нужно добавить текст, соответствующий записям. (см. формат в директории `data_path`)\n",
    "\n",
    "Но на 30-минутных записях не обучишься - давайте разобьем их на более короткие. Разбивать будем по участкам с тишиной - низкой энергией.\n",
    "\n",
    "Подберите параметры для такого сплита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f77b7",
   "metadata": {
    "id": "cd8f77b7",
    "outputId": "e466af08-cc5e-4df2-9051-6aa966dbf5cb"
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import auditok\n",
    "\n",
    "split_path = base_path / \"split\"\n",
    "\n",
    "split_args = {\n",
    "    \"min_dur\": <...>,\n",
    "    \"max_dur\": <...>,\n",
    "    \"max_silence\": <...>,\n",
    "    \"energy_threshold\": <...>,\n",
    "    # put other options you need here\n",
    "}\n",
    "\n",
    "def split(wav_path, output_dir, meta, split_args):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    wav = AudioSegment.from_wav(wav_path)\n",
    "    audio_regions = auditok.split(str(wav_path), **split_args)\n",
    "    \n",
    "    duration_in_seconds = 0\n",
    "    regions_count = 0\n",
    "    \n",
    "    for i, r in enumerate(audio_regions):\n",
    "        start = r.meta.start * 1000\n",
    "        end = r.meta.end * 1000\n",
    "        start = <...> # do you need any other adjustment?\n",
    "        end = <...>\n",
    "        duration_in_seconds += r.meta.end - r.meta.start\n",
    "        wav[start:end].export(\n",
    "            output_dir / f\"{meta}_{int(r.meta.start)}s.wav\",\n",
    "            format=\"wav\"\n",
    "        )\n",
    "    print(f\"Found {i} regions in track {wav_path} of duration {duration_in_seconds / 60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00caf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(split_path):\n",
    "    shutil.rmtree(split_path)  # clean up before each run to avoid looking at files from previous split\n",
    "\n",
    "\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        speaker = filename.split(\"_\")[0]\n",
    "        split(\n",
    "            wav_path=data_path / filename,\n",
    "            output_dir=split_path / speaker,\n",
    "            meta=filename[:-4],\n",
    "            split_args=split_args\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481a9e5",
   "metadata": {
    "id": "e481a9e5",
    "outputId": "0cebf5e4-c70b-46ae-bfce-156797499382"
   },
   "outputs": [],
   "source": [
    "# here is how dataset looks\n",
    "!ls {split_path}/obama | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0471ae7",
   "metadata": {
    "id": "a0471ae7"
   },
   "source": [
    "## 1.2 Генерация текстов\n",
    "\n",
    "В идеальном мире любые данные можно быстро разметить краудсорсингом. Но в реальности краудсорсинг медленный и недешевый, поэтому часть данных нужно стараться разметить автоматически. Мы реализуем такую разметку, а все записи в которых сомневаемся - удалим (оставшихся данных должно хватить).\n",
    "\n",
    "Шаг 1. Найти тексты к нашим записям и считать их.\n",
    "\n",
    "Шаг 2. Применить к нашим записям ASR.\n",
    "\n",
    "Шаг 3. Найти в текстах записи, соответствуеющие выходам ASR. Если два вида разметки совпадают, разметка близка к истине.\n",
    "\n",
    "Третий шаг будем делать с помощью библиотеки fuzzysearch - она ищет в большом тексте ближайший совпадающий текстовый отрезок.\n",
    "Алгоритм предлагаем реализовать такой:\n",
    "1. Посмотреть на найденную подстроку. Если его границы находятся в середине слова - добавим несколько символом слева и справа, чтобы все слова входили в подстроку полностью.\n",
    "2. По расстоянию Левенштейна проверить, что полученная строка примерно совпадает с исходной. Если расстояние слишком большое, то не будем включать наш пример в датасет.\n",
    "\n",
    "Валидируйте параметры матчинга на небольшом наборе записей, чтобы не запускать ASR несколько раз - каждый запуск может занять несколько часов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac53b26",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "6b7572cf1680424b9c58da374d1eafe7",
      "64b6538a34f74903a83cdc4a121e7ba2",
      "996b36c6b3754fe9b2c77504ac65b61c",
      "6709974951c54782bde75a8d7e756a14",
      "19575aebcd5849f1ba49ded709e51aa2"
     ]
    },
    "id": "5ac53b26",
    "outputId": "a8440326-4ff9-4b0e-9f12-4bd1b75ff0ca"
   },
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import EncoderDecoderASR\n",
    "\n",
    "asr_model = EncoderDecoderASR.from_hparams(\n",
    "    source=\"speechbrain/asr-crdnn-transformerlm-librispeech\",\n",
    "    savedir=\"pretrained_models/asr-crdnn-transformerlm-librispeech\",\n",
    "    run_opts={'device': 'cuda'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2c999",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "70080893e42041b28058d739b369d471"
     ]
    },
    "id": "e1c2c999",
    "outputId": "2c48ab74-6abd-487f-a4f3-7daaa41b015c"
   },
   "outputs": [],
   "source": [
    "import fuzzysearch\n",
    "import Levenshtein\n",
    "\n",
    "import data\n",
    "from utils import timeout\n",
    "\n",
    "def apply_asr(wav_path, text):\n",
    "    caption = asr_model.transcribe_file(str(wav_path)).lower()\n",
    "    if not caption:\n",
    "        return None\n",
    "\n",
    "    matches = timeout(\n",
    "        fuzzysearch.find_near_matches, args=[caption, text],\n",
    "        kwargs={'max_l_dist': <...>}, timeout_duration=3\n",
    "    )\n",
    "    if matches:\n",
    "        # DO NOT CUT MIDDLE OF THE WORD\n",
    "        l, r = matches[0].start, matches[0].end\n",
    "        # YOUR CODE HERE\n",
    "        l = <...>\n",
    "        r = <...>\n",
    "        matched_output = text[l:r].strip()\n",
    "\n",
    "        if Levenshtein.distance(caption, matched_output) < <...>:\n",
    "            return matched_output\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ASR ON THE DATASET\n",
    "\n",
    "texts = {}\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(data_path / filename) as f:\n",
    "            texts[filename[:-4]] = \" \".join(f.readlines())\n",
    "\n",
    "\n",
    "for spk in os.listdir(split_path):\n",
    "    print(\"Speaker:\", spk)\n",
    "    for filename in tqdm(os.listdir(split_path / spk)):\n",
    "        if not filename.endswith(\".wav\"):\n",
    "            continue\n",
    "        spk = filename.split(\"_\")[0]\n",
    "        tag = filename.split(\"_\")[1]\n",
    "        text = texts[f\"{spk}_{tag}\"]\n",
    "        filename = split_path / spk / filename\n",
    "        out_path = Path(filename).with_suffix('.lab')\n",
    "        caption = apply_asr(filename, text)\n",
    "        if caption:\n",
    "            with open(out_path, 'w') as f:\n",
    "                f.write(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JT0oV5qC1xgL",
   "metadata": {
    "id": "JT0oV5qC1xgL"
   },
   "source": [
    "- Посмотрите на оставшиеся и удаленные примеры. Как выбирались пороги ?\n",
    "\n",
    "- Посчитайте длину оставшихся для обучения данных. Для каждого спикера рекомендуем оставить не менее 15 минут, но модель способна обучиться и на 3 минутах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soTWjIge1vLW",
   "metadata": {
    "id": "soTWjIge1vLW"
   },
   "outputs": [],
   "source": [
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d1f1a",
   "metadata": {
    "id": "db9d1f1a"
   },
   "source": [
    "## 2. Генерация фичей\n",
    "\n",
    "Наша модель синтеза речи будет предсказывать следующие фичи:\n",
    "\n",
    "- алайнмент (длины каждой фонемы - целое число фреймов мел-спектрограммы)\n",
    "- энергию (коррелирует с громкостью) на каждом фрейме.\n",
    "- f0 (коррелирует с питчом) на каждом фрейме.\n",
    "\n",
    "При синтезе из текста эти фичи определят стиль и интонацию фразы. Также мы сможем сделать синтез, используя все эти фичи из оригинальной записи - чтобы оценить качество звука.\n",
    "\n",
    "f0 и энергии мы посчитаем сами - вам нужно будет только их нормализовать, чтобы модели было удобно работать с этими фичами.\n",
    "\n",
    "А вот алайнмент будем строить вместе. Запустим Montreal Force Aligner, чтобы узнать время начала и конца каждой фонемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5892d45",
   "metadata": {
    "id": "d5892d45",
    "outputId": "315f3221-c275-454d-f944-adfc42bf5449"
   },
   "outputs": [],
   "source": [
    "!source miniconda/bin/activate && \\\n",
    "    mfa g2p -j8 \\\n",
    "    english_g2p.zip \\\n",
    "    {split_path} {base_path}/phoneme_dict.txt\n",
    "    \n",
    "    \n",
    "!source miniconda/bin/activate && \\\n",
    "    mfa align --clean -j16 \\\n",
    "    {split_path} {base_path}/phoneme_dict.txt \\\n",
    "    english.zip \\\n",
    "    {base_path}/TextGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {base_path}/TextGrid/trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f046b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File type = \"ooTextFile\"\r\n",
      "Object class = \"TextGrid\"\r\n",
      "\r\n",
      "xmin = 0 \r\n",
      "xmax = 3.6985 \r\n",
      "tiers? <exists> \r\n",
      "size = 2 \r\n",
      "item []: \r\n",
      "    item [1]:\r\n",
      "        class = \"IntervalTier\" \r\n",
      "        name = \"words\" \r\n",
      "        xmin = 0 \r\n",
      "        xmax = 3.6985 \r\n",
      "        intervals: size = 13 \r\n",
      "        intervals [1]:\r\n",
      "            xmin = 0 \r\n",
      "            xmax = 0.18 \r\n",
      "            text = \"\" \r\n",
      "        intervals [2]:\r\n",
      "            xmin = 0.18 \r\n",
      "            xmax = 0.38 \r\n",
      "            text = \"we've\" \r\n",
      "        intervals [3]:\r\n",
      "            xmin = 0.38 \r\n",
      "            xmax = 0.92 \r\n",
      "            text = \"expanded\" \r\n",
      "        intervals [4]:\r\n",
      "            xmin = 0.92 \r\n",
      "            xmax = 1.04 \r\n",
      "            text = \"our\" \r\n",
      "        intervals [5]:\r\n",
      "            xmin = 1.04 \r\n",
      "            xmax = 1.45 \r\n",
      "            text = \"support\" \r\n",
      "        intervals [6]:\r\n",
      "            xmin = 1.45 \r\n",
      "            xmax = 1.55 \r\n",
      "            text = \"for\" \r\n",
      "        intervals [7]:\r\n",
      "            xmin = 1.55 \r\n",
      "            xmax = 1.81 \r\n",
      "            text = \"civil\" \r\n",
      "        intervals [8]:\r\n",
      "            xmin = 1.81 \r\n",
      "            xmax = 2.28 \r\n",
      "            text = \"society\" \r\n",
      "        intervals [9]:\r\n",
      "            xmin = 2.28 \r\n",
      "            xmax = 2.61 \r\n",
      "            text = \"groups\" \r\n",
      "        intervals [10]:\r\n",
      "            xmin = 2.61 \r\n",
      "            xmax = 2.7 \r\n",
      "            text = \"and\" \r\n",
      "        intervals [11]:\r\n",
      "            xmin = 2.7 \r\n",
      "            xmax = 2.96 \r\n",
      "            text = \"open\" \r\n",
      "        intervals [12]:\r\n",
      "            xmin = 2.96 \r\n",
      "            xmax = 3.33 \r\n",
      "            text = \"government\" \r\n",
      "        intervals [13]:\r\n",
      "            xmin = 3.33 \r\n",
      "            xmax = 3.6985 \r\n",
      "            text = \"\" \r\n",
      "    item [2]:\r\n",
      "        class = \"IntervalTier\" \r\n",
      "        name = \"phones\" \r\n",
      "        xmin = 0 \r\n",
      "        xmax = 3.6985 \r\n",
      "        intervals: size = 58 \r\n",
      "        intervals [1]:\r\n",
      "            xmin = 0 \r\n",
      "            xmax = 0.18 \r\n",
      "            text = \"\" \r\n",
      "        intervals [2]:\r\n",
      "            xmin = 0.18 \r\n",
      "            xmax = 0.27 \r\n",
      "            text = \"W\" \r\n",
      "        intervals [3]:\r\n",
      "            xmin = 0.27 \r\n",
      "            xmax = 0.32 \r\n",
      "            text = \"IY1\" \r\n",
      "        intervals [4]:\r\n",
      "            xmin = 0.32 \r\n",
      "            xmax = 0.38 \r\n",
      "            text = \"V\" \r\n",
      "        intervals [5]:\r\n",
      "            xmin = 0.38 \r\n",
      "            xmax = 0.42 \r\n",
      "            text = \"IH0\" \r\n",
      "        intervals [6]:\r\n",
      "            xmin = 0.42 \r\n",
      "            xmax = 0.48 \r\n",
      "            text = \"K\" \r\n",
      "        intervals [7]:\r\n",
      "            xmin = 0.48 \r\n",
      "            xmax = 0.56 \r\n",
      "            text = \"S\" \r\n",
      "        intervals [8]:\r\n",
      "            xmin = 0.56 \r\n",
      "            xmax = 0.63 \r\n",
      "            text = \"P\" \r\n",
      "        intervals [9]:\r\n",
      "            xmin = 0.63 \r\n",
      "            xmax = 0.75 \r\n",
      "            text = \"AE1\" \r\n",
      "        intervals [10]:\r\n",
      "            xmin = 0.75 \r\n",
      "            xmax = 0.79 \r\n",
      "            text = \"N\" \r\n",
      "        intervals [11]:\r\n",
      "            xmin = 0.79 \r\n",
      "            xmax = 0.82 \r\n",
      "            text = \"D\" \r\n",
      "        intervals [12]:\r\n",
      "            xmin = 0.82 \r\n",
      "            xmax = 0.86 \r\n",
      "            text = \"IH0\" \r\n",
      "        intervals [13]:\r\n",
      "            xmin = 0.86 \r\n",
      "            xmax = 0.92 \r\n",
      "            text = \"D\" \r\n",
      "        intervals [14]:\r\n",
      "            xmin = 0.92 \r\n",
      "            xmax = 0.96 \r\n",
      "            text = \"AW1\" \r\n",
      "        intervals [15]:\r\n",
      "            xmin = 0.96 \r\n",
      "            xmax = 1.04 \r\n",
      "            text = \"R\" \r\n",
      "        intervals [16]:\r\n",
      "            xmin = 1.04 \r\n",
      "            xmax = 1.11 \r\n",
      "            text = \"S\" \r\n",
      "        intervals [17]:\r\n",
      "            xmin = 1.11 \r\n",
      "            xmax = 1.17 \r\n",
      "            text = \"AH0\" \r\n",
      "        intervals [18]:\r\n",
      "            xmin = 1.17 \r\n",
      "            xmax = 1.27 \r\n",
      "            text = \"P\" \r\n",
      "        intervals [19]:\r\n",
      "            xmin = 1.27 \r\n",
      "            xmax = 1.35 \r\n",
      "            text = \"AO1\" \r\n",
      "        intervals [20]:\r\n",
      "            xmin = 1.35 \r\n",
      "            xmax = 1.41 \r\n",
      "            text = \"R\" \r\n",
      "        intervals [21]:\r\n",
      "            xmin = 1.41 \r\n",
      "            xmax = 1.45 \r\n",
      "            text = \"T\" \r\n",
      "        intervals [22]:\r\n",
      "            xmin = 1.45 \r\n",
      "            xmax = 1.48 \r\n",
      "            text = \"F\" \r\n",
      "        intervals [23]:\r",
      "\r\n",
      "            xmin = 1.48 \r\n",
      "            xmax = 1.51 \r\n",
      "            text = \"AO1\" \r\n",
      "        intervals [24]:\r\n",
      "            xmin = 1.51 \r\n",
      "            xmax = 1.55 \r\n",
      "            text = \"R\" \r\n",
      "        intervals [25]:\r\n",
      "            xmin = 1.55 \r\n",
      "            xmax = 1.65 \r\n",
      "            text = \"S\" \r\n",
      "        intervals [26]:\r\n",
      "            xmin = 1.65 \r\n",
      "            xmax = 1.68 \r\n",
      "            text = \"IH1\" \r\n",
      "        intervals [27]:\r\n",
      "            xmin = 1.68 \r\n",
      "            xmax = 1.72 \r\n",
      "            text = \"V\" \r\n",
      "        intervals [28]:\r\n",
      "            xmin = 1.72 \r\n",
      "            xmax = 1.75 \r\n",
      "            text = \"AH0\" \r\n",
      "        intervals [29]:\r\n",
      "            xmin = 1.75 \r\n",
      "            xmax = 1.81 \r\n",
      "            text = \"L\" \r\n",
      "        intervals [30]:\r\n",
      "            xmin = 1.81 \r\n",
      "            xmax = 1.88 \r\n",
      "            text = \"S\" \r\n",
      "        intervals [31]:\r\n",
      "            xmin = 1.88 \r\n",
      "            xmax = 1.93 \r\n",
      "            text = \"AH0\" \r\n",
      "        intervals [32]:\r\n",
      "            xmin = 1.93 \r\n",
      "            xmax = 2.04 \r\n",
      "            text = \"S\" \r\n",
      "        intervals [33]:\r\n",
      "            xmin = 2.04 \r\n",
      "            xmax = 2.16 \r\n",
      "            text = \"AY1\" \r\n",
      "        intervals [34]:\r\n",
      "            xmin = 2.16 \r\n",
      "            xmax = 2.2 \r\n",
      "            text = \"AH0\" \r\n",
      "        intervals [35]:\r\n",
      "            xmin = 2.2 \r\n",
      "            xmax = 2.23 \r\n",
      "            text = \"T\" \r\n",
      "        intervals [36]:\r\n",
      "            xmin = 2.23 \r\n",
      "            xmax = 2.28 \r\n",
      "            text = \"IY0\" \r\n",
      "        intervals [37]:\r\n",
      "            xmin = 2.28 \r\n",
      "            xmax = 2.34 \r\n",
      "            text = \"G\" \r\n",
      "        intervals [38]:\r\n",
      "            xmin = 2.34 \r\n",
      "            xmax = 2.39 \r\n",
      "            text = \"R\" \r\n",
      "        intervals [39]:\r\n",
      "            xmin = 2.39 \r\n",
      "            xmax = 2.45 \r\n",
      "            text = \"UW1\" \r\n",
      "        intervals [40]:\r\n",
      "            xmin = 2.45 \r\n",
      "            xmax = 2.56 \r\n",
      "            text = \"P\" \r\n",
      "        intervals [41]:\r\n",
      "            xmin = 2.56 \r\n",
      "            xmax = 2.61 \r\n",
      "            text = \"S\" \r\n",
      "        intervals [42]:\r\n",
      "            xmin = 2.61 \r\n",
      "            xmax = 2.64 \r\n",
      "            text = \"AE2\" \r\n",
      "        intervals [43]:\r\n",
      "            xmin = 2.64 \r\n",
      "            xmax = 2.67 \r\n",
      "            text = \"N\" \r\n",
      "        intervals [44]:\r\n",
      "            xmin = 2.67 \r\n",
      "            xmax = 2.7 \r\n",
      "            text = \"D\" \r\n",
      "        intervals [45]:\r\n",
      "            xmin = 2.7 \r\n",
      "            xmax = 2.78 \r\n",
      "            text = \"OW1\" \r\n",
      "        intervals [46]:\r\n",
      "            xmin = 2.78 \r\n",
      "            xmax = 2.85 \r\n",
      "            text = \"P\" \r\n",
      "        intervals [47]:\r\n",
      "            xmin = 2.85 \r\n",
      "            xmax = 2.88 \r\n",
      "            text = \"AH0\" \r\n",
      "        intervals [48]:\r\n",
      "            xmin = 2.88 \r\n",
      "            xmax = 2.96 \r\n",
      "            text = \"N\" \r\n",
      "        intervals [49]:\r\n",
      "            xmin = 2.96 \r\n",
      "            xmax = 3.02 \r\n",
      "            text = \"G\" \r\n",
      "        intervals [50]:\r\n",
      "            xmin = 3.02 \r\n",
      "            xmax = 3.09 \r\n",
      "            text = \"AH1\" \r\n",
      "        intervals [51]:\r\n",
      "            xmin = 3.09 \r\n",
      "            xmax = 3.14 \r\n",
      "            text = \"V\" \r\n",
      "        intervals [52]:\r\n",
      "            xmin = 3.14 \r\n",
      "            xmax = 3.18 \r\n",
      "            text = \"ER0\" \r\n",
      "        intervals [53]:\r\n",
      "            xmin = 3.18 \r\n",
      "            xmax = 3.21 \r\n",
      "            text = \"N\" \r\n",
      "        intervals [54]:\r\n",
      "            xmin = 3.21 \r\n",
      "            xmax = 3.24 \r\n",
      "            text = \"M\" \r\n",
      "        intervals [55]:\r\n",
      "            xmin = 3.24 \r\n",
      "            xmax = 3.27 \r\n",
      "            text = \"AH0\" \r\n",
      "        intervals [56]:\r\n",
      "            xmin = 3.27 \r\n",
      "            xmax = 3.3 \r\n",
      "            text = \"N\" \r\n",
      "        intervals [57]:\r\n",
      "            xmin = 3.3 \r\n",
      "            xmax = 3.33 \r\n",
      "            text = \"T\" \r\n",
      "        intervals [58]:\r\n",
      "            xmin = 3.33 \r\n",
      "            xmax = 3.6985 \r\n",
      "            text = \"\" \r\n"
     ]
    }
   ],
   "source": [
    "!cat /Users/andrewgolman/shad_task/tests/alignment.TextGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462c3a5",
   "metadata": {
    "id": "0462c3a5"
   },
   "source": [
    "## 2.1 Извлечение алайнмента\n",
    "\n",
    "Мы получили начало и конец фонемы в секундах. Теперь нужно перевести их в фреймы мел-спектрограммы, а также округлить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a09ad3",
   "metadata": {
    "id": "05a09ad3"
   },
   "outputs": [],
   "source": [
    "def get_alignment(textgrid, sampling_rate, hop_length):\n",
    "    phoneme_info = textgrid.tierDict['phones'].entryList\n",
    "    phones = []\n",
    "    durations = []\n",
    "\n",
    "    for t in phoneme_info:\n",
    "        if t.label == \"\":\n",
    "            continue\n",
    "        phones.append(t.label)\n",
    "        start = t.start\n",
    "        end = t.end\n",
    "        ## YOUR CODE HERE\n",
    "        duration_in_frames = <...>\n",
    "        durations.append(\n",
    "            duration_in_frames\n",
    "        )\n",
    "    return phones, durations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import tgio\n",
    "assert np.allclose(\n",
    "    get_alignment(\n",
    "        tgio.openTextgrid(\"tests/alignment.TextGrid\", readRaw=True), 22050, 256\n",
    "    )[1],\n",
    "    np.load(\"tests/alignment.npy\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0884be",
   "metadata": {
    "id": "8b0884be"
   },
   "source": [
    "Теперь можно запустить препроцессинг датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5b635",
   "metadata": {
    "id": "a5f5b635"
   },
   "outputs": [],
   "source": [
    "from praatio import tgio\n",
    "import pyworld as pw\n",
    "import data\n",
    "\n",
    "\n",
    "def extract_features(speaker, base_path, basename):\n",
    "    tg_path = base_path / \"TextGrid\" / speaker / f\"{basename}.TextGrid\"\n",
    "    wav_path = base_path / \"split\" / speaker / f\"{basename}.wav\"\n",
    "    if not os.path.exists(tg_path):\n",
    "        print(\"WARNING: no textgrid for basename\", basename)\n",
    "        return False\n",
    "    \n",
    "\n",
    "    textgrid = tgio.openTextgrid(tg_path, readRaw=True)\n",
    "    phone, duration = get_alignment(\n",
    "        textgrid,\n",
    "        data_cfg.sampling_rate,\n",
    "        data_cfg.hop_length\n",
    "    )\n",
    "\n",
    "    wav, _ = librosa.load(str(wav_path))\n",
    "\n",
    "    mel, energy = data.extract_mel_energy(wav, sum(duration), data_cfg)\n",
    "    f0 = data.extract_f0(wav, sum(duration), data_cfg)\n",
    "\n",
    "    features = {\n",
    "        'phone': phone,\n",
    "        'energy': energy,\n",
    "        'mel': mel,\n",
    "        'f0': f0,\n",
    "        'alignment': duration,\n",
    "    }\n",
    "    \n",
    "    for key, feat in features.items():\n",
    "        if feat is None:\n",
    "            return False\n",
    "        np.save(base_path / key / f\"{key}-{basename}.npy\", feat)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_type in ['phone', 'energy', 'mel', 'f0', 'alignment']:\n",
    "    os.makedirs(base_path / feature_type, exist_ok=True)\n",
    "\n",
    "for spk in os.listdir(split_path):\n",
    "    spk_path = split_path / spk\n",
    "    for filename in tqdm(os.listdir(spk_path)):\n",
    "        if not filename.endswith(\".wav\"):\n",
    "            continue\n",
    "        basename = filename[:-4]\n",
    "        extract_features(spk, base_path, basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9aec02",
   "metadata": {
    "id": "ac9aec02"
   },
   "source": [
    "## 2.2 Смотрим на ненормализованные фичи\n",
    "\n",
    "f0 и energy лежат в директориях `{base_path}/f0` и `{base_path}/energy`.\n",
    "\n",
    "Визуализируйте несколько примеров f0 и energy. Послушайте соответствующие записи, соотнесите скачки интонации со скачками фичей. Можно ли угадать интонацию предложения, посмотрев только на f0 и energy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5134d441",
   "metadata": {
    "id": "5134d441"
   },
   "outputs": [],
   "source": [
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a26597",
   "metadata": {
    "id": "48a26597"
   },
   "source": [
    "Скопируем данные VCTK в наш датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c63ed",
   "metadata": {
    "id": "027c63ed"
   },
   "outputs": [],
   "source": [
    "for feature_type in ['phone', 'energy', 'mel', 'f0', 'alignment']:\n",
    "    for fn in tqdm(os.listdir(vctk_path / feature_type)):\n",
    "        shutil.copy(vctk_path / feature_type / fn, base_path / feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e2879",
   "metadata": {
    "id": "e28e2879"
   },
   "source": [
    "## 2.3 Нормализация фичей\n",
    "\n",
    "f0 и energy модель будет учить через MSE, при этом в этих фичах довольно много выбросов. Нормализуйте фичи, удалите выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907ef9f",
   "metadata": {
    "id": "c907ef9f"
   },
   "outputs": [],
   "source": [
    "<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11be55",
   "metadata": {
    "id": "4d11be55"
   },
   "source": [
    "Следующая ячейка построит статистики по получившемуся датасету: модели потребуются эти статистики, чтобы предсказывать f0 и energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd9141",
   "metadata": {
    "id": "e0bd9141"
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import json\n",
    "\n",
    "train_filenames, dev_filenames, speakers = data.train_test_split(base_path)\n",
    "feature_stat = data.build_feature_stat(base_path, train_filenames)\n",
    "\n",
    "with open(base_path / \"speakers.json\", \"w\") as f:\n",
    "    json.dump({v: k for k, v in enumerate(speakers)}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c5903",
   "metadata": {
    "id": "204c5903"
   },
   "source": [
    "## 3.1 Реализация модели\n",
    "\n",
    "Ниже приведена реализация FastSpeech2 для единственного спикера.\n",
    "\n",
    "Но в нашей модели помимо фичей на вход модели будет подаваться эмбеддинг, соответствующий спикеру. Добавьте в модель этот эмбеддинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8569ca4",
   "metadata": {
    "id": "e8569ca4"
   },
   "outputs": [],
   "source": [
    "data_cfg.update(feature_stat)\n",
    "model_cfg = OmegaConf.load(\"conf/model.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745afc57",
   "metadata": {
    "id": "745afc57",
    "outputId": "6c9aa04f-7006-4ea2-f640-09e25d0a22c6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformer.Models import Encoder, Decoder\n",
    "from transformer.Layers import PostNet\n",
    "from utils import get_mask_from_lengths\n",
    "from modules import VarianceAdaptor\n",
    "\n",
    "\n",
    "class FastSpeech2(nn.Module):\n",
    "    \"\"\" FastSpeech2 \"\"\"\n",
    "\n",
    "    def __init__(self, speaker_num, mel_channels, cfg, variance_cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(cfg)\n",
    "        self.speaker_embedding = <...>\n",
    "        self.variance_adaptor = VarianceAdaptor(\n",
    "            cfg,\n",
    "            f0_min=variance_cfg.f0_min,\n",
    "            f0_max=variance_cfg.f0_max,\n",
    "            energy_min=variance_cfg.energy_min,\n",
    "            energy_max=variance_cfg.energy_max,\n",
    "        )\n",
    "        self.decoder = Decoder(cfg)\n",
    "        self.mel_linear = nn.Linear(cfg.decoder_hidden, mel_channels)\n",
    "        self.postnet = PostNet(postnet_kernel_size=5)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src_seq,\n",
    "        src_len,\n",
    "        mel_len=None,\n",
    "        d_target=None,\n",
    "        p_target=None,\n",
    "        e_target=None,\n",
    "        max_src_len=None,\n",
    "        max_mel_len=None,\n",
    "        speaker=None, # [BATCH_SIZE]\n",
    "        speaker_embedding=None, # [BATCH_SIZE, SPEAKER_EMBEDDING_SIZE] (need this if we want to infer with an embedding not present in training data)\n",
    "    ):\n",
    "        src_mask = get_mask_from_lengths(src_len, max_src_len)\n",
    "        mel_mask = (\n",
    "            get_mask_from_lengths(mel_len, max_mel_len) if mel_len is not None else None\n",
    "        )\n",
    "\n",
    "        encoder_output = self.encoder(src_seq, src_mask)\n",
    "        if speaker is not None:\n",
    "            if speaker_embedding is None:\n",
    "                <...>\n",
    "            encoder_output = <...>\n",
    "\n",
    "        (\n",
    "            variance_adaptor_output,\n",
    "            d_prediction,\n",
    "            d_rounded,\n",
    "            p_prediction,\n",
    "            e_prediction,\n",
    "            mel_len,\n",
    "            mel_mask,\n",
    "        ) = self.variance_adaptor(\n",
    "            encoder_output,\n",
    "            encoder_output,\n",
    "            src_mask,\n",
    "            mel_mask,\n",
    "            d_target,\n",
    "            p_target,\n",
    "            e_target,\n",
    "            max_mel_len,\n",
    "        )\n",
    "\n",
    "        decoder_output = self.decoder(variance_adaptor_output, mel_mask)\n",
    "        mel_output = self.mel_linear(decoder_output)\n",
    "        mel_output_postnet = self.postnet(mel_output) + mel_output\n",
    "\n",
    "        return (\n",
    "            mel_output,\n",
    "            mel_output_postnet,\n",
    "            d_prediction,\n",
    "            d_rounded,\n",
    "            p_prediction,\n",
    "            e_prediction,\n",
    "            src_mask,\n",
    "            mel_mask,\n",
    "            mel_len,\n",
    "        )\n",
    "    \n",
    "speaker_num = <...>\n",
    "model = FastSpeech2(\n",
    "    speaker_num, data_cfg.n_mel_channels, model_cfg, data_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45477b3",
   "metadata": {
    "id": "e45477b3"
   },
   "source": [
    "## 3.2 Обучение модели\n",
    "\n",
    "Задание все еще про аналитику, так что обучение модели можно не писать:)\n",
    "\n",
    "Тем не менее, стоит посмотреть на графики обучения (они пишутся в директорию logs в загружаемом в tensorboard формате), а также на примеры, которое модель синтезирует каждые 1000 итераций. Останавливайте обучение, когда качество достигнет приемлемого - не раньше через 50 тысяч итераций, но лучше - 100 тысяч. На VCTK разумного качества получится достигнуть быстрее. Для большинства следующих пунктов можно пользоваться инференсом только на примерах из VCTK.\n",
    "\n",
    "Рекомендуем заглянуть в конфиг и настроить сохранение почаще, если работаете в колабе. Можно будет указать cfg.restore_step и продолжить обучение с нужного места."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9db93",
   "metadata": {
    "id": "b0b9db93"
   },
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "train_cfg = OmegaConf.load(\"conf/train.yaml\")\n",
    "train(train_cfg, model_cfg, data_cfg, base_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f928a",
   "metadata": {
    "id": "144f928a"
   },
   "source": [
    "## 4 Анализ модели\n",
    "\n",
    "Пора инферить модель. Что можно делать:\n",
    "\n",
    "1. Инферить тестовую выборку с gt-фичами (ground-truth) и predicted-фичами. Насколько помогают gt-фичи качеству звука? А естественности речи?\n",
    "1. Найти несколько ошибок в длинах фонем. Посмотреть на обучающие данные - какие закономерности в них могли привести к ошибкам?\n",
    "1. Изменить интонацию в синтезируемых примерах за счет ручного редактирования фичей. Как различаются предсказания фичей у разных спикеров?\n",
    "1. Визуализировать эмбеддинги спикеров. Что можно сказать про пространство? Действительно ли эмбеддинги похожих спикеров близки друг к другу?\n",
    "1. Сделать синтез с эмбеддингом отсутствовавшего в исходной выборке спикера: например, среднего между мужским и женским голосом (пользуйтесь параметром speaker_embedding). В каких ситуациях получается стабильный голос?\n",
    "1. Синтезировать примеры Стива Джобса из двух его выступлений с gt-фичами и predicted-фичами. Одинаковое ли качество звука на двух выступлениях? Могут ли влиять фичи на качество звука?\n",
    "1. Воспользоваться другим предобученным вокодером. На каких спикерах удалось улучшить качество?\n",
    "1. Дообучить модель на примерах своего голоса. Получилось ли похоже?\n",
    "\n",
    "За каждый пункт будет ставиться 2 балла: 1 балл за код и полученные аудио, 1 балл за выводы. В сумме до 8 баллов, с учетом бонусов - до 12.\n",
    "\n",
    "### Hints:\n",
    "\n",
    "\n",
    "2 способа перевода текста в фонемы:\n",
    "1. (правильный) G2P модель от MFA (см. первый вызов MFA в этом ноутбуке)\n",
    "2. (не совсем правильный, но простой) Через библиотеку g2p_en: для большинства случаев этот способ хорош, в некоторых кейсах фонемы будут отличаться от выхода MFA (а значит, и от обучающей выборки).\n",
    "\n",
    "    ```\n",
    "    from g2p_en import G2p\n",
    "\n",
    "    g2p = G2p()\n",
    "    \n",
    "    phonemes = g2p(word)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b6151",
   "metadata": {
    "id": "760b6151"
   },
   "source": [
    "Небольшая документация про то, какие параметры передавать на вход инференсу:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d8775",
   "metadata": {
    "id": "787d8775"
   },
   "source": [
    "```\n",
    "speaker_ids = id for each item in batch\n",
    "texts = list of np.array[str] of phonemes\n",
    "mel_len = None or frame count for each sample (take it from original mel lengths)\n",
    "Ds = None or list of np.arrays[PHONEME_COUNT] with phoneme lengths. Sum should be equal to mel_len\n",
    "f0s = None or list of np.array[FRAME_COUNT]. Do not use it when alignment is None\n",
    "energies = None or list of np.array[FRAME_COUNT]. Do not use it when alignment is None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"ckpt/checkpoint_60000.pth.tar\")\n",
    "model = nn.DataParallel(model).cuda()\n",
    "model.load_state_dict(ckpt['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = \"obama_1_100s\"\n",
    "speaker = \"obama\"\n",
    "\n",
    "speaker_ids = [speakers[speaker]]\n",
    "texts = [np.load(base_path / \"phone\" / f\"phone-{basename}.npy\")]\n",
    "f0s = [np.load(base_path / \"f0\" / f\"f0-{basename}.npy\")]\n",
    "Ds = [np.load(base_path / \"alignment\" / f\"alignment-{basename}.npy\")]\n",
    "mel_len = [Ds[0].sum()]\n",
    "energies = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5890da",
   "metadata": {
    "id": "cf5890da"
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import synthesise\n",
    "\n",
    "<YOUR CODE HERE>\n",
    "\n",
    "wavs, mels, Ds, f0s, energies = synthesise.synthesize(\n",
    "    model,\n",
    "    data_cfg,\n",
    "    speaker_ids,\n",
    "    texts,\n",
    "    mel_len,\n",
    "    Ds,\n",
    "    f0s,\n",
    "    energies,\n",
    ")\n",
    "\n",
    "for wav in wavs[:10]:\n",
    "    display(Audio(wav, rate=22050))\n",
    "    sf.write(f\"output/{task_id}_{spk}_{basename}.wav\", wav, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR EXPERIMENTS HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e4cf0",
   "metadata": {
    "id": "7a0e4cf0"
   },
   "source": [
    "В LMS присылайте архив с решением: вложите туда ноутбук и примеры синтеза, которые вы анализировали. Начинайте названия файлов с номера пункта задания."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a2d56530"
   ],
   "name": "shad.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
